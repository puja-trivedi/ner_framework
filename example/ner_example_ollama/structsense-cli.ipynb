{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089cf773-5a8e-47e8-8fb8-04054b195cb2",
   "metadata": {},
   "source": [
    "# Install structsense and makesure GROBID is running. Use the command below.\n",
    "\n",
    "```shell\n",
    "docker pull lfoppiano/grobid:0.8.0\n",
    "docker run --init -p 8070:8070 -e JAVA_OPTS=\"-XX:+UseZGC\" lfoppiano/grobid:0.8.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637454f-04d0-44cc-a1c4-7235bee34310",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install structsense --quiet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64a6973-fbbc-479f-bf5c-85725f94541f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: structsense-cli [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  CLI commands for the Structsense Framework application\n",
      "\n",
      "Options:\n",
      "  --help  Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  extract  Extract the terms along with sentence.\n"
     ]
    }
   ],
   "source": [
    "!structsense-cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6801df16-eab8-4c36-91fa-3a69010f4e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: structsense-cli extract [OPTIONS]\n",
      "\n",
      "  Extract the terms along with sentence.\n",
      "\n",
      "Options:\n",
      "  --agentconfig TEXT      Path to the agent configuration in YAML file format\n",
      "                          or dictionary  [required]\n",
      "  --taskconfig TEXT       Path to the agent task configuration in YAML format\n",
      "                          or or dictionary  [required]\n",
      "  --embedderconfig TEXT   Path to the embedding configuration in YAML format\n",
      "                          or or dictionary  [required]\n",
      "  --flowconfig TEXT       Path to the flow configuration in YAML format or or\n",
      "                          dictionary. The flow configuration describes the\n",
      "                          flow of the agent.  [required]\n",
      "  --knowledgeconfig TEXT  Path to the configuration in YAML format or or\n",
      "                          dictionary that specify the search knowledge search\n",
      "                          key.\n",
      "  --source TEXT           The sourceâ€”whether a file (text or PDF), a folder,\n",
      "                          or a text string.  [required]\n",
      "  --help                  Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!structsense-cli extract --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5af4c7-7cba-4bd3-a375-460acfd07a96",
   "metadata": {},
   "source": [
    "# Set Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8490e7fb-49e4-4a5e-995b-db14a7696970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ENABLE_WEIGHTSANDBIAS=false\n",
      "env: ENABLE_MLFLOW=false\n",
      "env: ENABLE_KG_SOURCE=false\n",
      "env: ONTOLOGY_DATABASE=Ontology_database_agent_test #note this is my local vectordatabase name, we need this because ENABLE_KG_SOURCE=true\n",
      "env: WEAVIATE_API_KEY=\"XFG!NQmUVEC&8\" #note this is my local vectordatabase key\n",
      "env: OLLAMA_API_ENDPOINT=http://host.docker.internal:11434 #note this is my local vectordatabase name\n",
      "env: OLLAMA_MODEL=nomic-embed-text #note this is my local vectordatabase name\n"
     ]
    }
   ],
   "source": [
    "%env ENABLE_WEIGHTSANDBIAS=false\n",
    "%env ENABLE_MLFLOW=false\n",
    "%env ENABLE_KG_SOURCE=false\n",
    "%env ONTOLOGY_DATABASE=Ontology_database_agent_test #note this is my local vectordatabase name, we need this because ENABLE_KG_SOURCE=true\n",
    "%env WEAVIATE_API_KEY=\"XFG!NQmUVEC&8\" #note this is my local vectordatabase key\n",
    "%env OLLAMA_API_ENDPOINT=http://host.docker.internal:11434 #note this is my local vectordatabase name\n",
    "%env OLLAMA_MODEL=nomic-embed-text #note this is my local vectordatabase name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee709161-3acd-4536-b9b9-2833c92379ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mcrew_memory\u001b[m\u001b[m           \u001b[34mner_config\u001b[m\u001b[m            structsense-cli.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4effa86e-bba4-4b5d-9175-a96acb1153ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.yaml                 ner_task.yaml\n",
      "flow_ner.yaml                  search_ontology_knowledge.yaml\n",
      "ner_agent.yaml\n"
     ]
    }
   ],
   "source": [
    "!ls ner_config/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a9254d-02e3-4dde-9de0-bb0845441acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agents:\n",
      "  - id: extractor_agent\n",
      "    output_variable: extracted_info\n",
      "    role: >\n",
      "      Neuroscience Named Entity Recognition (NER) Extractor Agent\n",
      "    goal: >\n",
      "      Perform Named Entity Recognition (NER) on neuroscience {literature} and return structured JSON output.\n",
      "    backstory: >\n",
      "      You are an AI assistant specialized in processing neuroscience and who do not hallucinate. \n",
      "      Your expertise includes recognizing and categorizing named entities such as anatomical regions, experimental conditions, and cell types. \n",
      "      Your responses strictly adhere to JSON format, ensuring accurate and structured data extraction for downstream applications.\n",
      "    llm:\n",
      "      model: ollama/deepseek-r1:14b\n",
      "      base_url: http://localhost:11434\n",
      "      seed: 53\n",
      "\n",
      "  - id: alignment_agent\n",
      "    output_variable: aligned_structured_terms\n",
      "    role: >\n",
      "      Neuroscience Named Entity Recognition (NER) Concept Alignment Agent\n",
      "    goal: >\n",
      "      Perform concept alignment to the extracted Named Entity Recognition (NER) by extractor_agent {extracted_info} and return structured JSON output.\n",
      "    backstory: >\n",
      "      You are an AI assistant specialized in processing neuroscience concept alignment with structured models, i.e., ontologies or schemas and who do not hallucinate. \n",
      "      Your expertise includes recognizing and categorizing extracted named entities such as anatomical regions, experimental conditions, and cell types and aligning the recognized named entities such as cell types with corresponding ontological terms. \n",
      "      Your responses strictly adhere to JSON format, ensuring accurate and structured data extraction for downstream applications.\n",
      "    llm:\n",
      "      model: ollama/deepseek-r1:14b\n",
      "      base_url: http://localhost:11434\n",
      "      seed: 53\n",
      "\n",
      "  - id: judge_agent\n",
      "    output_variable: aligned_judged_terms\n",
      "    role: >\n",
      "      Neuroscience Named Entity Recognition (NER) Judge Agent\n",
      "    goal: >\n",
      "      Evaluate the {aligned_structured_terms} based on predefined criteria and generate a structured JSON output reflecting the assessment results.\n",
      "    backstory: >\n",
      "      You are an AI assistant with expert knowledge in neuroscience and structured models, i.e., ontologies or schemas, and someone who does not hallucinate.  \n",
      "      Your task is to evaluate the {aligned_structured_terms} based on the accuracy and quality of the alignment. \n",
      "      Assign the score between 0-1 with 1 being the highest score of your evaluation.\n",
      "      Your responses strictly adhere to JSON format, ensuring accurate and structured data extraction for downstream applications.\n",
      "    llm:\n",
      "      model: ollama/deepseek-r1:14b\n",
      "      base_url: http://localhost:11434\n",
      "      seed: 53\n"
     ]
    }
   ],
   "source": [
    "! cat ner_config/ner_agent.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93626f4f-7cc4-4748-8467-1b3cb4a9a067",
   "metadata": {},
   "source": [
    "# Extract from a PDF file (with knowledge source)\n",
    "\n",
    "Input: https://www.biorxiv.org/content/10.1101/2025.03.06.641914v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905a1bf-4bbb-47a9-a359-260d5c7f1688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-02 15:33:41,800 - structsense.cli - INFO - Processing source: test.pdf with agent config: ner_config/ner_agent.yaml, task config: ner_config/ner_task.yaml, embedderconfig: ner_config/embedding.yaml, flowconfig: ner_config/flow_ner.yaml, knowledgeconfig: ner_config/search_ontology_knowledge.yaml\n",
      "Processing source: test.pdf with agent config: ner_config/ner_agent.yaml, task config: ner_config/ner_task.yaml, embedderconfig: ner_config/embedding.yaml knowledgeconfig: ner_config/search_ontology_knowledge.yaml flowconfig: ner_config/flow_ner.yaml\n",
      "2025-04-02 15:33:41,801 - utils.utils - INFO - Trying paths: ['test.pdf', '/Users/tekrajchhetri/Documents/brainypedia_codes_design/crew_ner_framework/structsense/example/ner_example_ollama/test.pdf', '/Users/tekrajchhetri/Documents/brainypedia_codes_design/crew_ner_framework/structsense/example/ner_example_ollama/test.pdf', '/Users/tekrajchhetri/Documents/brainypedia_codes_design/crew_ner_framework/structsense/example/ner_example_ollama/test.pdf']\n",
      "2025-04-02 15:33:41,801 - utils.utils - INFO - Using path: test.pdf\n",
      "2025-04-02 15:33:41,801 - utils.utils - INFO - Processing single file: test.pdf\n"
     ]
    }
   ],
   "source": [
    "!structsense-cli extract --agentconfig ner_config/ner_agent.yaml --taskconfig ner_config/ner_task.yaml --embedderconfig ner_config/embedding.yaml --flowconfig ner_config/flow_ner.yaml --knowledgeconfig ner_config/search_ontology_knowledge.yaml --source test.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a9a29d-bcd7-4814-b3fc-404ba231ae60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df9a8a-a2e3-48ad-aba7-d6766a6777c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
